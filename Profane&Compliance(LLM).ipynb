{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb4ef7-3be3-4f32-8bde-ce721465bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install google-generativeai tqdm ujson pyyaml seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae382797-e7d3-47cf-982c-a7e6d044b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports + API key\n",
    "\n",
    "import os, glob, zipfile, re, unicodedata, ujson, json, yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "# ---- Paste your Gemini API key here ----\n",
    "genai.configure(api_key=\"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415ad41-f184-4ad2-9325-d2a62146c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) ZIP path (local file) + extract\n",
    "\n",
    "import shutil\n",
    "\n",
    "# ---- Set the path to your ZIP on disk (relative or absolute) ----\n",
    "ZIP_PATH = r\"C:\\Users\\Sanglap\\Desktop\\Prodigal Assignment\\All_Conversations.zip\"  # e.g., \"./transcripts.zip\"\n",
    "if not ZIP_PATH or not ZIP_PATH.lower().endswith(\".zip\"):\n",
    "    raise SystemExit(f\"Please set ZIP_PATH to a .zip file (got: {ZIP_PATH})\")\n",
    "if not os.path.exists(ZIP_PATH):\n",
    "    raise SystemExit(f\"ZIP not found at: {ZIP_PATH}\")\n",
    "\n",
    "EXTRACT_DIR = \"./data\"\n",
    "OUT_DIR = \"./outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_JSONL = os.path.join(OUT_DIR, \"gemini_analysis.jsonl\")\n",
    "OUT_SUMMARY_CSV = os.path.join(OUT_DIR, \"summary.csv\")\n",
    "\n",
    "# Clean and extract\n",
    "if os.path.exists(EXTRACT_DIR):\n",
    "    shutil.rmtree(EXTRACT_DIR)\n",
    "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(ZIP_PATH, \"r\") as zf:\n",
    "    zf.extractall(EXTRACT_DIR)\n",
    "\n",
    "# Recursively find JSON/YAML files (skip noise dirs)\n",
    "EXCLUDED_DIRS = {\".ipynb_checkpoints\", \"__MACOSX\", \".git\", \".svn\"}\n",
    "files = []\n",
    "for dirpath, dirnames, filenames in os.walk(EXTRACT_DIR):\n",
    "    dirnames[:] = [d for d in dirnames if d not in EXCLUDED_DIRS and not d.startswith(\".\")]\n",
    "    for fn in filenames:\n",
    "        if fn.lower().endswith((\".json\", \".yaml\", \".yml\")) and not fn.startswith(\".\"):\n",
    "            files.append(os.path.join(dirpath, fn))\n",
    "\n",
    "files = sorted(files)\n",
    "print(f\"Extracted to: {EXTRACT_DIR}\")\n",
    "print(f\"Discovered {len(files)} transcript file(s). Showing up to 10:\")\n",
    "for p in files[:10]:\n",
    "    print(\" -\", p)\n",
    "if not files:\n",
    "    raise SystemExit(\"No .json/.yaml/.yml files found inside the ZIP.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a91b21-e6b8-47a6-8452-cb26379074d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) YOUR GEMINI MODEL CODE \n",
    "\n",
    "\n",
    "# --- Set up Gemini API ---\n",
    "# Re-configure Gemini API in case of kernel reset\n",
    "try:\n",
    "    genai.get_model('gemini-1.5-flash-latest')\n",
    "except Exception:\n",
    "    print(\"Configuring Gemini API...\")\n",
    "    # IMPORTANT: Replace with your actual API key or retrieve it securely\n",
    "    genai.configure(api_key='....')\n",
    "\n",
    "# --- Define Gemini Prompt ---\n",
    "# Using the prompt defined that includes profanity instructions\n",
    "GEMINI_PII_SYSTEM_PROMPT_WITH_PROFANITY = \"\"\"You are an expert compliance and conversation analysis assistant, specializing in precise identification of profanity and sensitive information disclosure within customer service transcripts. Your analysis must be strictly objective, based solely on the provided text, and adhere to the defined rules and output format.\n",
    "\n",
    "*INPUT FORMAT:*\n",
    "You will receive a conversation transcript as a sequence of indexed utterances. Each utterance is formatted as:\n",
    "[index] SPEAKER: text\n",
    "\n",
    "- [index]: A 0-based integer representing the utterance's position in the original transcript. *Crucially, these indices must be preserved exactly in your output.*\n",
    "- SPEAKER: Will always be one of two predefined roles: AGENT or CUSTOMER.\n",
    "- text: The spoken content of the utterance.\n",
    "\n",
    "*PRIMARY OBJECTIVES:*\n",
    "Your task is to generate an analysis that provides the following two key checks:\n",
    "1.  *Profanity Detection:* Identify all instances of profanity, noting the exact offending phrase, the speaker, and the utterance index.\n",
    "2.  *Privacy/Compliance Audit (PII Disclosure):* Determine if the AGENT disclosed any sensitive account information before the CUSTOMER's identity was successfully verified.\n",
    "\n",
    "*KEY DEFINITIONS (Strict Interpretation Required):*\n",
    "\n",
    "A.  *PROFANITY:*\n",
    "    -   *Definition:* Any explicit offensive, vulgar, or abusive terms. This includes, but is not limited to, common curse words (e.g., f*ck, sh*t, a**hole, b*tch, damn, hell, crap, ass), and their common variants or obfuscated forms (e.g., f@#k, f u c k, ffffuu…, sh!t, a$$hole). Slur variants are also included.\n",
    "    -   *Detection Rule:* You must identify and extract the exact substring as it appears in the utterance text. Do not normalize, infer, or invent text that is not explicitly present.\n",
    "    -   *Output Format for Profanity:* Each detected instance must be represented as an object with speaker, text (the exact offending phrase), and index (the utterance index). Collect all instances into a list.\n",
    "\n",
    "B.  *IDENTITY VERIFICATION (“verification”):*\n",
    "    -   *Definition:* The process by which the AGENT confirms the CUSTOMER's identity using specific Personally Identifiable Information (PII).\n",
    "    -   *Acceptable Verification Signals (PII):*\n",
    "        -   *Date of Birth (DOB):* Full date of birth (e.g., MM/DD/YYYY) or components (e.g., month, day, year) that, when combined, constitute a full DOB.\n",
    "        -   *Full Address:* Complete street address including street number, street name, city, state, and ZIP code, or a combination of street name and ZIP code.\n",
    "        -   *Social Security Number (SSN):* Full SSN or the last four digits (last-4) of the SSN. This also applies to equivalent government IDs.\n",
    "    -   *Verification Event Completion:* A verification event is considered successfully completed only when both conditions are met:\n",
    "        1.  The AGENT explicitly requests one or more of the acceptable PII signals.\n",
    "        2.  The CUSTOMER provides or confirms the correct information in response to the AGENT's request.\n",
    "        3.  Alternatively, the AGENT explicitly states that verification was successful (e.g., “Okay, I’ve verified your identity.”).\n",
    "    -   *What is NOT Verification:*\n",
    "        -   Mere confirmation of name, phone number, or email address.\n",
    "        -   Caller ID information.\n",
    "        -   Generic security questions that do not involve specific PII (e.g., “Can you confirm your account?” without subsequent PII exchange).\n",
    "        -   Partial verification where the CUSTOMER refuses to provide the requested PII (e.g., AGENT asks for last-4 SSN, but CUSTOMER declines).\n",
    "\n",
    "C.  *SENSITIVE DISCLOSURE (“disclosure”):*\n",
    "    -   *Definition:* The AGENT revealing specific, private account or balance details to the CUSTOMER.\n",
    "    -   *Examples of Sensitive Information:*\n",
    "        -   Current balance, amount due, or amount owed.\n",
    "        -   Exact dollar amounts related to the account (e.g., “Your balance is $X.XX”).\n",
    "        -   Full or partial account numbers (e.g., last-4 digits of an account number).\n",
    "        -   Payment due dates.\n",
    "        -   Last payment amount or date.\n",
    "        -   Any other data that explicitly confirms the CUSTOMER’s private account state or transaction history.\n",
    "    -   *What is NOT Disclosure:*\n",
    "        -   Generic policy statements or disclaimers (e.g., “We cannot discuss your account until we verify your identity.”).\n",
    "        -   Salutations, on-hold notices, or filler words, unless they contain sensitive information.\n",
    "    -   *Important Edge Case:* If the CUSTOMER states a sensitive detail (e.g., an amount) first, and the AGENT then confirms or corrects that detail before successful identity verification, this still counts as an AGENT disclosure.\n",
    "\n",
    "**DECISION RULES FOR pii_disclosure_without_verification FLAG:**\n",
    "This boolean flag (true or false) indicates a compliance violation.\n",
    "\n",
    "-   **Set to true IF:** Any AGENT disclosure (as defined in C) occurs before the first successful identity verification event (as defined in B) in the transcript.\n",
    "-   **Set to false IF:**\n",
    "    -   Successful identity verification occurs before any AGENT disclosure.\n",
    "    -   There are AGENT disclosures, but they all occur after the first successful verification.\n",
    "    -   There is no AGENT disclosure at all in the transcript.\n",
    "-   *Ambiguity Resolution:* If there is any uncertainty or lack of explicit evidence in the transcript to confirm a violation, you must default to false. Provide a brief rationale citing the relevant indices for your decision.\n",
    "\n",
    "*OUTPUT FORMAT (Structured Text):*\n",
    "Provide your analysis in the following structured format. Do not include any other commentary or conversational text.\n",
    "\n",
    "Profanity instances: [list of profanity objects, e.g., [{\"speaker\": \"CUSTOMER\", \"text\": \"f*ck\", \"index\": 1}, ...]]\n",
    "PII disclosure before verification: [true/false]\n",
    "Rationale: [brief explanation, citing relevant utterance indices]\n",
    "Verification indices: [list of 0-based utterance indices, e.g., [3, 4]]\n",
    "Disclosure indices: [list of 0-based utterance indices, e.g., [2]]\n",
    "\n",
    "*FINAL INSTRUCTION:*\n",
    "Analyze the provided transcript and provide your analysis ONLY in the specified format.\n",
    "\"\"\"\n",
    "\n",
    "# --- Helper function to parse raw text output from Gemini ---\n",
    "def analyze_transcript_gemini_with_profanity_raw_text(gemini_output_text: str) -> Dict[str, Any]:\n",
    "    result = {\n",
    "        'profanity': [],\n",
    "        'pii_disclosure_without_verification': False,\n",
    "        'rationale': 'Parsing failed or information not found.',\n",
    "        'checked_verification_indices': [],\n",
    "        'disclosure_indices': []\n",
    "    }\n",
    "\n",
    "    if not gemini_output_text:\n",
    "        return result\n",
    "\n",
    "    text_lower = gemini_output_text.lower()\n",
    "\n",
    "    # Profanity instances\n",
    "    profanity_match = re.search(r\"profanity instances:\\s*(\\[.*?\\])\", text_lower, re.DOTALL)\n",
    "    if profanity_match:\n",
    "        profanity_str = profanity_match.group(1)\n",
    "        try:\n",
    "            profanity_str_clean = profanity_str.strip()\n",
    "            if profanity_str_clean.endswith(','):\n",
    "                 profanity_str_clean = profanity_str_clean[:-1] + ']'\n",
    "            profanity_list = json.loads(profanity_str_clean)\n",
    "            result['profanity'] = [\n",
    "                item for item in profanity_list\n",
    "                if isinstance(item, dict) and 'speaker' in item and 'text' in item and 'index' in item\n",
    "            ]\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Failed to parse profanity list: {profanity_str}\")\n",
    "            result['profanity'] = []\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Error processing profanity list: {e}\")\n",
    "             result['profanity'] = []\n",
    "\n",
    "    # PII disclosure flag\n",
    "    pii_match = re.search(r\"pii disclosure before verification:\\s*(true|false)\", text_lower)\n",
    "    if pii_match:\n",
    "        result['pii_disclosure_without_verification'] = pii_match.group(1) == 'true'\n",
    "    else:\n",
    "        result['pii_disclosure_without_verification'] = False\n",
    "\n",
    "    # Rationale\n",
    "    rationale_match = re.search(r\"rationale:\\s*(.*?)(?=verification indices:|disclosure indices:|profanity instances:|$)\", text_lower, re.DOTALL)\n",
    "    if rationale_match:\n",
    "        result['rationale'] = rationale_match.group(1).strip()\n",
    "    elif 'PII disclosure flag not found' not in result['rationale']:\n",
    "         result['rationale'] = 'Rationale section not found.'\n",
    "\n",
    "    # Verification indices\n",
    "    verification_indices_match = re.search(r\"verification indices:\\s*(\\[.*?\\])\", text_lower)\n",
    "    if verification_indices_match:\n",
    "        indices_str = verification_indices_match.group(1)\n",
    "        try:\n",
    "            indices_list = json.loads(indices_str)\n",
    "            result['checked_verification_indices'] = [int(i) for i in indices_list if isinstance(i, (int, float))]\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Failed to parse verification indices list: {indices_str}\")\n",
    "            result['checked_verification_indices'] = []\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Error processing verification indices list: {e}\")\n",
    "             result['checked_verification_indices'] = []\n",
    "\n",
    "    # Disclosure indices\n",
    "    disclosure_indices_match = re.search(r\"disclosure indices:\\s*(\\[.*?\\])\", text_lower)\n",
    "    if disclosure_indices_match:\n",
    "        indices_str = disclosure_indices_match.group(1)\n",
    "        try:\n",
    "            indices_list = json.loads(indices_str)\n",
    "            result['disclosure_indices'] = [int(i) for i in indices_list if isinstance(i, (int, float))]\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Failed to parse disclosure indices list: {indices_str}\")\n",
    "            result['disclosure_indices'] = []\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing disclosure indices list: {e}\")\n",
    "            result['disclosure_indices'] = []\n",
    "\n",
    "    # Ensure keys\n",
    "    required_keys = ['profanity', 'pii_disclosure_without_verification', 'rationale', 'checked_verification_indices', 'disclosure_indices']\n",
    "    for key in required_keys:\n",
    "        if key not in result:\n",
    "             result[key] = [] if 'indices' in key or 'profanity' in key else (False if 'pii_disclosure' in key else 'Missing key in Gemini output.')\n",
    "\n",
    "    return result\n",
    "\n",
    "# --- Gemini Analysis Function ---\n",
    "def analyze_transcript_gemini_with_profanity(utts: List[Dict[str, str]]) -> Dict[str, Any]:\n",
    "    # Build the user message\n",
    "    user_message_lines = []\n",
    "    for i, utt in enumerate(utts):\n",
    "        speaker = utt.get('speaker', 'UNKNOWN').strip().upper()\n",
    "        text = utt.get('text', '').strip()\n",
    "        user_message_lines.append(f\"[{i}] {speaker}: {text}\")\n",
    "    user_message = \"Transcript:\\n\" + \"\\n\".join(user_message_lines) + \"\\n\\nAnalyze and provide the output in the specified format.\"\n",
    "\n",
    "    # Create model\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=GEMINI_PII_SYSTEM_PROMPT_WITH_PROFANITY)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Gemini model instance: {e}\")\n",
    "        return {\n",
    "            'profanity': [],\n",
    "            'pii_disclosure_without_verification': False,\n",
    "            'rationale': f'Gemini model instantiation failed: {e}',\n",
    "            'checked_verification_indices': [],\n",
    "            'disclosure_indices': []\n",
    "        }\n",
    "\n",
    "    # Generate\n",
    "    try:\n",
    "        response = model.generate_content(user_message)\n",
    "        gemini_output_text = response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating content from Gemini model: {e}\")\n",
    "        return {\n",
    "            'profanity': [],\n",
    "            'pii_disclosure_without_verification': False,\n",
    "            'rationale': f'Gemini content generation failed: {e}',\n",
    "            'checked_verification_indices': [],\n",
    "            'disclosure_indices': []\n",
    "        }\n",
    "\n",
    "    return analyze_transcript_gemini_with_profanity_raw_text(gemini_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867c2f5-0f73-4479-bf26-eb7fdcc8b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) MAIN PROCESSING\n",
    "\n",
    "processed_count = 0\n",
    "failed_files = []\n",
    "all_analysis_results = []  # Store results for JSONL and CSV\n",
    "\n",
    "files_to_process = files  # ALL files\n",
    "print(f\"Processing all {len(files_to_process)} files.\")\n",
    "\n",
    "# Clear the output files if they exist\n",
    "if os.path.exists(OUT_JSONL):\n",
    "    os.remove(OUT_JSONL)\n",
    "\n",
    "# Processing loop - Using Gemini for both PII/Disclosure and Profanity\n",
    "with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for file_path in tqdm(files_to_process, desc=\"Processing files with Gemini\"):\n",
    "        try:\n",
    "            # Load data from JSON or YAML\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f_in:\n",
    "                if file_path.lower().endswith(\".json\"):\n",
    "                    data = json.load(f_in)\n",
    "                else:  # YAML/YML\n",
    "                    data = yaml.safe_load(f_in)\n",
    "\n",
    "            # Ensure data is list of dicts with 'speaker' and 'text'\n",
    "            if not isinstance(data, list) or not all(isinstance(item, dict) and 'speaker' in item and 'text' in item for item in data):\n",
    "                print(f\"Skipping file {file_path}: Data is not in expected list-of-dicts format.\")\n",
    "                failed_files.append((file_path, \"Incorrect data format\"))\n",
    "                continue\n",
    "\n",
    "            # Analyze with Gemini\n",
    "            gemini_analysis = analyze_transcript_gemini_with_profanity(data)\n",
    "\n",
    "            combined = {\n",
    "                'original_file': os.path.basename(file_path),\n",
    "                'profanity': gemini_analysis.get('profanity', []),\n",
    "                'pii_disclosure_without_verification': gemini_analysis.get('pii_disclosure_without_verification', False),\n",
    "                'rationale': gemini_analysis.get('rationale', 'Gemini analysis failed or incomplete'),\n",
    "                'checked_verification_indices': gemini_analysis.get('checked_verification_indices', []),\n",
    "                'disclosure_indices': gemini_analysis.get('disclosure_indices', [])\n",
    "            }\n",
    "\n",
    "            all_analysis_results.append(combined)\n",
    "            f_out.write(ujson.dumps(combined, ensure_ascii=False) + '\\n')\n",
    "            processed_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            failed_files.append((file_path, str(e)))\n",
    "            all_analysis_results.append({\n",
    "                'original_file': os.path.basename(file_path),\n",
    "                'profanity': [],\n",
    "                'pii_disclosure_without_verification': False,\n",
    "                'rationale': f'Processing failed: {e}',\n",
    "                'checked_verification_indices': [],\n",
    "                'disclosure_indices': []\n",
    "            })\n",
    "\n",
    "print(f\"\\nFinished processing. Successfully processed {processed_count} files.\")\n",
    "if failed_files:\n",
    "    print(f\"Failed to process {len(failed_files)} files:\")\n",
    "    for fname, error in failed_files:\n",
    "        print(f\"- {fname}: {error}\")\n",
    "\n",
    "print(f\"Per-file JSONL saved to {OUT_JSONL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68bda84-9ea1-492d-b191-751320fd1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) SUMMARY \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "simple_rows = []\n",
    "\n",
    "for item in all_analysis_results:\n",
    "    file_name = item.get(\"original_file\", \"N_A\")\n",
    "    call_id   = os.path.splitext(os.path.basename(file_name))[0]\n",
    "\n",
    "    prof_list = item.get(\"profanity\", []) or []\n",
    "    # Normalize speakers to uppercase; treat CALLER as CUSTOMER\n",
    "    agent_hits = [p for p in prof_list if str(p.get(\"speaker\",\"\")).strip().upper() == \"AGENT\"]\n",
    "    cust_hits  = [p for p in prof_list if str(p.get(\"speaker\",\"\")).strip().upper() in {\"CUSTOMER\",\"CALLER\"}]\n",
    "\n",
    "    profane_words_agent    = bool(agent_hits)\n",
    "    profane_words_customer = bool(cust_hits)\n",
    "\n",
    "    agent_profane_words_count    = len(agent_hits)\n",
    "    customer_profane_words_count = len(cust_hits)\n",
    "\n",
    "    disclosed_before_verify = bool(item.get(\"pii_disclosure_without_verification\", False))\n",
    "\n",
    "    simple_rows.append({\n",
    "        \"call_id\": call_id,\n",
    "        \"profane_words_agent\": profane_words_agent,\n",
    "        \"profane_words_customer\": profane_words_customer,\n",
    "        \"agent_profane_words_count\": agent_profane_words_count,\n",
    "        \"customer_profane_words_count\": customer_profane_words_count,\n",
    "        \"disclosed_before_verify\": disclosed_before_verify,\n",
    "    })\n",
    "\n",
    "simple_df = pd.DataFrame(simple_rows).sort_values(\"call_id\").reset_index(drop=True)\n",
    "\n",
    "# Save the simplified per-call summary\n",
    "simple_df.to_csv(OUT_SUMMARY_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"Simple per-call summary saved to: {OUT_SUMMARY_CSV}\")\n",
    "display(simple_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa1ffa-774d-4db7-9c97-952e2bd64583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Post-run counts — counts for the simple per-call summary CSV ===\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "assert os.path.exists(OUT_SUMMARY_CSV), f\"CSV not found: {OUT_SUMMARY_CSV}\"\n",
    "df = pd.read_csv(OUT_SUMMARY_CSV)\n",
    "\n",
    "def _as_bool_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce mixed True/False/string/None into boolean with NaN for unknown.\"\"\"\n",
    "    if s is None:\n",
    "        return pd.Series([np.nan] * len(df))\n",
    "    def _c(v):\n",
    "        if isinstance(v, bool): return v\n",
    "        if pd.isna(v): return np.nan\n",
    "        sv = str(v).strip().lower()\n",
    "        if sv in (\"true\",\"1\",\"yes\"):  return True\n",
    "        if sv in (\"false\",\"0\",\"no\"):  return False\n",
    "        return np.nan\n",
    "    return s.map(_c)\n",
    "\n",
    "# Booleans\n",
    "prof_agent = _as_bool_series(df[\"profane_words_agent\"]) \\\n",
    "             if \"profane_words_agent\" in df.columns else pd.Series([np.nan]*len(df))\n",
    "prof_cust  = _as_bool_series(df[\"profane_words_customer\"]) \\\n",
    "             if \"profane_words_customer\" in df.columns else pd.Series([np.nan]*len(df))\n",
    "disclose   = _as_bool_series(df[\"disclosed_before_verify\"]) \\\n",
    "             if \"disclosed_before_verify\" in df.columns else pd.Series([np.nan]*len(df))\n",
    "\n",
    "# Numeric counts\n",
    "agent_cnt = pd.to_numeric(df[\"agent_profane_words_count\"], errors=\"coerce\") \\\n",
    "             if \"agent_profane_words_count\" in df.columns else pd.Series([np.nan]*len(df))\n",
    "cust_cnt  = pd.to_numeric(df[\"customer_profane_words_count\"], errors=\"coerce\") \\\n",
    "             if \"customer_profane_words_count\" in df.columns else pd.Series([np.nan]*len(df))\n",
    "\n",
    "# High-level aggregates\n",
    "AGG_COUNTS = {\n",
    "    \"calls_total\": int(len(df)),\n",
    "\n",
    "    \"calls_profane_agent_true\": int((prof_agent == True).sum()),\n",
    "    \"calls_profane_agent_false\": int((prof_agent == False).sum()),\n",
    "    \"calls_profane_agent_missing\": int(prof_agent.isna().sum()),\n",
    "\n",
    "    \"calls_profane_customer_true\": int((prof_cust == True).sum()),\n",
    "    \"calls_profane_customer_false\": int((prof_cust == False).sum()),\n",
    "    \"calls_profane_customer_missing\": int(prof_cust.isna().sum()),\n",
    "\n",
    "    \"calls_disclosed_before_verify_true\": int((disclose == True).sum()),\n",
    "    \"calls_disclosed_before_verify_false\": int((disclose == False).sum()),\n",
    "    \"calls_disclosed_before_verify_missing\": int(disclose.isna().sum()),\n",
    "}\n",
    "\n",
    "# Per-column value distributions (exclude identifier)\n",
    "COUNTS_BY_COLUMN = {\n",
    "    col: df[col].value_counts(dropna=False).to_dict()\n",
    "    for col in df.columns\n",
    "    if col != \"call_id\"\n",
    "}\n",
    "\n",
    "# Single merged object if you want to export/inspect\n",
    "AGG_COUNTS_ALL = {\n",
    "    \"summary\": AGG_COUNTS,\n",
    "    \"by_column\": COUNTS_BY_COLUMN,\n",
    "}\n",
    "\n",
    "# Peek\n",
    "print(\"AGG_COUNTS =\", AGG_COUNTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37c890-d66b-4bed-b801-f2c4ce5bcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create a NEW summary CSV that includes utterance numbers per role (does NOT overwrite the original) ===\n",
    "# Prereqs:\n",
    "#   - OUT_SUMMARY_CSV already exists (your per-call summary)\n",
    "#   - Preferably OUT_JSONL exists (the detailed per-file records saved by the main run)\n",
    "#      Each JSONL line should have keys: file_name, profanity_list, disclosed_before_verify, verify_indices, disclosure_indices, note\n",
    "#   - If OUT_JSONL is missing, this will try a fallback column 'profanity_list_json' in the summary CSV (if you added it earlier)\n",
    "\n",
    "import os, json, ujson, pandas as pd\n",
    "\n",
    "assert os.path.exists(OUT_SUMMARY_CSV), f\"CSV not found: {OUT_SUMMARY_CSV}\"\n",
    "df_sum = pd.read_csv(OUT_SUMMARY_CSV)\n",
    "\n",
    "NEW_SUMMARY_CSV = os.path.join(OUT_DIR, \"gemini_summary.csv\")\n",
    "\n",
    "def _call_id_from_file_name(file_name: str) -> str:\n",
    "    base = os.path.basename(str(file_name))\n",
    "    return os.path.splitext(base)[0]\n",
    "\n",
    "def _extract_nums_from_prof_list(prof_list):\n",
    "    \"\"\"Return (agent_nums, customer_nums) as sorted lists of 1-based utterance numbers.\"\"\"\n",
    "    agent_nums, customer_nums = [], []\n",
    "    for p in (prof_list or []):\n",
    "        try:\n",
    "            spk = str(p.get(\"speaker\", \"\")).strip().upper()\n",
    "            idx0 = p.get(\"index\", None)\n",
    "            idx1 = (int(idx0) + 1) if isinstance(idx0, (int, float)) else None\n",
    "            if idx1 is None:\n",
    "                continue\n",
    "            if spk == \"AGENT\":\n",
    "                agent_nums.append(idx1)\n",
    "            elif spk in {\"CUSTOMER\", \"CALLER\"}:\n",
    "                customer_nums.append(idx1)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return sorted(agent_nums), sorted(customer_nums)\n",
    "\n",
    "# --- Build lookup of call_id -> (agent_nums, customer_nums) ---\n",
    "call_to_nums = {}\n",
    "source_used = None\n",
    "\n",
    "if os.path.exists(OUT_JSONL):\n",
    "    source_used = \"jsonl\"\n",
    "    with open(OUT_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rec = ujson.loads(line)\n",
    "                file_name = rec.get(\"file_name\", \"N_A\")\n",
    "                call_id = _call_id_from_file_name(file_name)\n",
    "                prof_list = rec.get(\"profanity_list\", []) or []\n",
    "                agent_nums, customer_nums = _extract_nums_from_prof_list(prof_list)\n",
    "                call_to_nums[call_id] = (agent_nums, customer_nums)\n",
    "            except Exception:\n",
    "                continue\n",
    "elif \"profanity_list_json\" in df_sum.columns:\n",
    "    source_used = \"csv_jsoncol\"\n",
    "    for _, row in df_sum.iterrows():\n",
    "        try:\n",
    "            prof_list = row[\"profanity_list_json\"]\n",
    "            if isinstance(prof_list, str):\n",
    "                prof_list = json.loads(prof_list)\n",
    "        except Exception:\n",
    "            prof_list = []\n",
    "        agent_nums, customer_nums = _extract_nums_from_prof_list(prof_list)\n",
    "        call_to_nums[str(row.get(\"call_id\", \"N_A\"))] = (agent_nums, customer_nums)\n",
    "else:\n",
    "    source_used = \"none\"\n",
    "\n",
    "# --- Create augmented copy of the original summary without overwriting it ---\n",
    "df_aug = df_sum.copy()\n",
    "\n",
    "if source_used == \"none\":\n",
    "    # No detailed source available; still create the new CSV with empty columns\n",
    "    df_aug[\"agent_profane_utterance_nos\"] = \"\"\n",
    "    df_aug[\"customer_profane_utterance_nos\"] = \"\"\n",
    "    print(\n",
    "        \"Could not populate utterance numbers:\\n\"\n",
    "        \"- OUT_JSONL not found, and\\n\"\n",
    "        \"- 'profanity_list_json' column not present in the summary CSV.\\n\"\n",
    "        \"Saving a new CSV with empty utterance-number columns.\"\n",
    "    )\n",
    "else:\n",
    "    agent_col = []\n",
    "    cust_col = []\n",
    "    for _, row in df_aug.iterrows():\n",
    "        call_id = str(row.get(\"call_id\", \"N_A\"))\n",
    "        a_nums, c_nums = call_to_nums.get(call_id, ([], []))\n",
    "        agent_col.append(\", \".join(map(str, a_nums)) if a_nums else \"\")\n",
    "        cust_col.append(\", \".join(map(str, c_nums)) if c_nums else \"\")\n",
    "    df_aug[\"agent_profane_utterance_nos\"] = agent_col\n",
    "    df_aug[\"customer_profane_utterance_nos\"] = cust_col\n",
    "    print(f\"Utterance numbers populated from: {source_used}\")\n",
    "\n",
    "# Save to a NEW file\n",
    "df_aug.to_csv(NEW_SUMMARY_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"New summary (with utterance numbers) saved to: {NEW_SUMMARY_CSV}\")\n",
    "display(df_aug.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4002a-723d-48ac-bd71-7bf469cb5e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_cu121)",
   "language": "python",
   "name": "env_cu121"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
